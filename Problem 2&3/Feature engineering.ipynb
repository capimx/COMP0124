{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP0124: Multi-Agent Artificial Intelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group project: Real-time bidding auctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Group #7: Oliviero Balbinetti, Mauricio Caballero, Paul Melkert**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T08:49:21.393034Z",
     "start_time": "2019-02-20T08:49:21.389288Z"
    }
   },
   "source": [
    "Importing libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T18:32:23.815220Z",
     "start_time": "2019-03-01T18:32:23.038744Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections as coll\n",
    "\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T18:32:24.209405Z",
     "start_time": "2019-03-01T18:32:24.186922Z"
    }
   },
   "outputs": [],
   "source": [
    "#Feature map file.\n",
    "def Feature_map_gen(Data, Features, Column, Maps, Special_maps, Index):\n",
    "    \n",
    "    #Indexing columns for outliers.\n",
    "    for col_idx in range(0,len(Data.columns)):\n",
    "        Column[Data.columns[col_idx]] = col_idx\n",
    "        \n",
    "        if col_idx > 0:\n",
    "            Features[str(col_idx) + ':other'] = Index\n",
    "            Index += 1\n",
    "            \n",
    "    #Regular maps.\n",
    "    for col_idx in Maps:\n",
    "        content = list(set(Data[col_idx]))\n",
    "        \n",
    "        for item in content:\n",
    "            feature = str(Column[col_idx]) + ':' + str(item)\n",
    "            Features[feature] = Index\n",
    "            Index += 1\n",
    "            \n",
    "    #Special maps.\n",
    "    for col_idx in Special_maps:\n",
    "        \n",
    "        if col_idx == 'useragent':\n",
    "            content = list(set(Data[col_idx]))\n",
    "            \n",
    "            for item in content:\n",
    "                feature = str(Column[col_idx]) + ':' + str(item)\n",
    "                Features[feature] = Index\n",
    "                Index += 1\n",
    "                \n",
    "        if col_idx == 'slotprice':\n",
    "            content = list(set(Data[col_idx]))\n",
    "            \n",
    "            for item in content:\n",
    "                if item > 100: value = '101+'\n",
    "                elif item > 50: value = '51-100'\n",
    "                elif item > 10: value = '11-50'\n",
    "                elif item > 0: value = '1-10'\n",
    "                else: value = '0'\n",
    "                \n",
    "                feature = str(Column[col_idx]) + ':' + value\n",
    "                Features[feature] = Index\n",
    "                Index += 1\n",
    "                \n",
    "    #User tags.\n",
    "    Temp = [item for sublist in Data['usertag list'] for item in sublist]\n",
    "    Tags = list(set(Temp))\n",
    "    \n",
    "    for tag in Tags:\n",
    "        feature = str(Column['usertag']) + ':' + tag\n",
    "        Features[feature] = Index\n",
    "        Index += 1\n",
    "        \n",
    "    print('Feature vectors size: %d' %Index)\n",
    "    Outcome = sorted(Features.items(), key=operator.itemgetter(1))\n",
    "    return Outcome\n",
    "    \n",
    "#Logistic regression files.\n",
    "def Logistic_regression_gen(Data, Features, Column, Maps, Special_maps):\n",
    "    Outcome = Data['bidid'] + ',' + Data['click'].map(str) + ','\\\n",
    "              + Data['payprice'].map(str) + ',' + '0'\n",
    "    \n",
    "    #Regular maps.\n",
    "    for col_idx in Maps:\n",
    "        List = []\n",
    "        idx = Column[col_idx]\n",
    "        \n",
    "        y = str(idx) + ':' + 'other'\n",
    "        content = str(idx) + ':' + Data[col_idx].map(str)\n",
    "        for x in content:\n",
    "            try: \n",
    "                List.append(Features[x]) \n",
    "            except: \n",
    "                List.append(Features[y])\n",
    "        \n",
    "        values = pd.Series(List)\n",
    "        Outcome += ' ' + values.map(str)\n",
    "        \n",
    "    #Special maps.\n",
    "    for col_idx in Maps:\n",
    "        List = []\n",
    "        idx = Column[col_idx]\n",
    "        \n",
    "        if col_idx == 'useragent':\n",
    "            y = str(idx) + ':' + 'other'\n",
    "            content = str(idx) + ':' + Data[col_idx].map(str)\n",
    "            for x in content:\n",
    "                try: \n",
    "                    List.append(Features[x]) \n",
    "                except: \n",
    "                    List.append(Features[y])\n",
    "        \n",
    "            values = pd.Series(List)\n",
    "            Outcome += ' ' + values.map(str)\n",
    "            \n",
    "        if col_idx == 'slotprice':\n",
    "            List = []\n",
    "            Temp = []\n",
    "            Array = Data[col_idx].values\n",
    "            \n",
    "            for item in Array:\n",
    "                if item > 100: Temp.append('101+')\n",
    "                elif item > 50: Temp.append('51-100')\n",
    "                elif item > 10: Temp.append('11-50')\n",
    "                elif item > 0: Temp.append('1-10')\n",
    "                else: Temp.append('0')\n",
    "                \n",
    "            y = str(idx) + ':' + 'other'\n",
    "            content = str(idx) + ':' + pd.Series(Temp)\n",
    "            for x in content:\n",
    "                try: \n",
    "                    List.append(Features[x]) \n",
    "                except: \n",
    "                    List.append(Features[y])\n",
    "            \n",
    "            values = pd.Series(List)\n",
    "            Outcome += ' ' + values.map(str)\n",
    "            \n",
    "    #User tags.\n",
    "    mapped = []\n",
    "    idx = Column['usertag']\n",
    "    Tags = list(Data['usertag list'].values)\n",
    "    \n",
    "    for sublist in Tags:\n",
    "        List = []\n",
    "        y = str(idx) + ':' + 'other'\n",
    "        content = str(idx) + ':' + pd.Series(sublist)\n",
    "        for x in content:\n",
    "            try: \n",
    "                List.append(Features[x]) \n",
    "            except: \n",
    "                List.append(Features[y])\n",
    "        \n",
    "        values = pd.Series(List)\n",
    "        joined = list(' ' + values.map(str))\n",
    "        mapped.append(''.join(joined))\n",
    "        \n",
    "    Outcome += pd.Series(mapped).map(str)\n",
    "    return Outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing data in pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T18:33:10.515769Z",
     "start_time": "2019-03-01T18:32:25.204360Z"
    }
   },
   "outputs": [],
   "source": [
    "#Defining directory.\n",
    "Path = '/Users/olivierobalbinetti/Desktop/University College London/Term 2'\\\n",
    "       '/Multi Agents Artificial Intelligence/Courseworks/Group coursework/'\\\n",
    "       'Data/Original'\n",
    "\n",
    "#Importing data.\n",
    "Datasets = {}\n",
    "os.chdir(Path)\n",
    "\n",
    "for Filename in glob('*.csv'):\n",
    "    Datasets[Filename[:-4].title()] = pd.read_csv(Filename, sep = ',')\n",
    "    \n",
    "#Defining variables.\n",
    "Test = Datasets['Test']\n",
    "Train = Datasets['Train']\n",
    "Validation = Datasets['Validation']\n",
    "\n",
    "#Feature engineering: ad exchange.\n",
    "Test['adexchange'] = Test['adexchange'].fillna('nan')\n",
    "Train['adexchange'] = Train['adexchange'].fillna('nan')\n",
    "Validation['adexchange'] = Validation['adexchange'].fillna('nan')\n",
    "\n",
    "#Feature engineering: slot size.\n",
    "Test['slotsize'] = Test['slotwidth'].astype('str') + '*' +\\\n",
    "                   Test['slotheight'].astype('str')\n",
    "Train['slotsize'] = Train['slotwidth'].astype('str') + '*' +\\\n",
    "                    Train['slotheight'].astype('str')\n",
    "Validation['slotsize'] = Validation['slotwidth'].astype('str') + '*' +\\\n",
    "                         Validation['slotheight'].astype('str')\n",
    "\n",
    "#Feature engineering: browser user agent.\n",
    "Temp = Train['useragent'].str.split('_', n=1, expand=True)\n",
    "Train['OS'] = Temp[0]\n",
    "Train['Browser'] = Temp[1]\n",
    "\n",
    "Temp = Test['useragent'].str.split('_', n=1, expand=True)\n",
    "Test['OS'] = Temp[0]\n",
    "Test['Browser'] = Temp[1]\n",
    "\n",
    "Temp = Validation['useragent'].str.split('_', n=1, expand=True)\n",
    "Validation['OS'] = Temp[0]\n",
    "Validation['Browser'] = Temp[1]\n",
    "\n",
    "#Feature engineering: user tags.\n",
    "Train['usertag'] = Train['usertag'].fillna('nan')                      #Train.\n",
    "Train['usertag list'] = Train['usertag'].str.split(',').values\n",
    "Temp = list(Train['usertag list'].values)\n",
    "Tags = [item for sublist in Temp for item in sublist]\n",
    "\n",
    "Dict = dict(coll.Counter(Tags).most_common())\n",
    "Dict['nan'] = max(Dict.values())+1\n",
    "Dict = dict(sorted(Dict.items(), key=lambda kv: kv[1], reverse=True))\n",
    "Dict = dict(enumerate(Dict.keys()))\n",
    "\n",
    "Dict = {value:key for key,value in Dict.items()}\n",
    "Dict['nan'] = 'nan'\n",
    "Train = Train.assign(mapped=[[Dict[k] for k in row if Dict.get(k)]\n",
    "                             for row in Train['usertag list'].values])\n",
    "\n",
    "\n",
    "Test['usertag'] = Test['usertag'].fillna('nan')                         #Test.\n",
    "Test['usertag list'] = Test['usertag'].str.split(',').values\n",
    "Temp = list(Test['usertag list'].values)\n",
    "Tags = [item for sublist in Temp for item in sublist]\n",
    "\n",
    "Dict = dict(coll.Counter(Tags).most_common())\n",
    "Dict['nan'] = max(Dict.values())+1\n",
    "Dict = dict(sorted(Dict.items(), key=lambda kv: kv[1], reverse=True))\n",
    "Dict = dict(enumerate(Dict.keys()))\n",
    "\n",
    "Dict = {value:key for key,value in Dict.items()}\n",
    "Dict['nan'] = 'nan'\n",
    "Test = Test.assign(mapped=[[Dict[k] for k in row if Dict.get(k)]\n",
    "                           for row in Test['usertag list'].values])\n",
    "\n",
    "\n",
    "Validation['usertag'] = Validation['usertag'].fillna('nan')       #Validation.\n",
    "Validation['usertag list'] = Validation['usertag'].str.split(',').values\n",
    "Temp = list(Validation['usertag list'].values)\n",
    "Tags = [item for sublist in Temp for item in sublist]\n",
    "\n",
    "Dict = dict(coll.Counter(Tags).most_common())\n",
    "Dict['nan'] = max(Dict.values())+1\n",
    "Dict = dict(sorted(Dict.items(), key=lambda kv: kv[1], reverse=True))\n",
    "Dict = dict(enumerate(Dict.keys()))\n",
    "\n",
    "Dict = {value:key for key,value in Dict.items()}\n",
    "Dict['nan'] = 'nan'\n",
    "Validation = Validation.assign(mapped=[[Dict[k] for k in row if Dict.get(k)]\n",
    "                                       for row in Validation['usertag list'].values])\n",
    "\n",
    "#Feature engineering: renaming.\n",
    "Test = Test.rename(columns={'mapped':'tagcodes'})\n",
    "Train = Train.rename(columns={'mapped':'tagcodes'})\n",
    "Validation = Validation.rename(columns={'mapped':'tagcodes'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T19:07:44.684081Z",
     "start_time": "2019-03-01T18:33:10.517535Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering for logistic regression CTR estimation:\n",
      "\n",
      "Feature vectors size: 580325\n",
      "• [File Feature_map.csv]: Process completed!\n",
      "\n",
      "• [File Train.csv]: Process completed!\n",
      "• [File Validation.csv]: Process completed!\n"
     ]
    }
   ],
   "source": [
    "#Feature engineering files.\n",
    "print('Feature engineering for logistic regression CTR estimation:\\n')\n",
    "Path = '/Users/olivierobalbinetti/Desktop/University College London/Term 2/'\\\n",
    "       'Multi Agents Artificial Intelligence/Courseworks/Group coursework/'\\\n",
    "       'Data/Feature engineering'\n",
    "\n",
    "#Defining general variables.\n",
    "Index = 0\n",
    "Column = {}\n",
    "Features = {}\n",
    "\n",
    "Maps = ['weekday', 'hour', 'IP', 'region', 'city', 'adexchange', 'domain',\n",
    "        'slotid', 'slotwidth', 'slotheight', 'slotvisibility', 'slotformat',\n",
    "        'creative', 'advertiser']\n",
    "Special_maps = ['useragent', 'slotprice']\n",
    "\n",
    "#Saving map file.\n",
    "os.chdir(Path)\n",
    "Features['truncate'] = Index\n",
    "Header = 'Column:Value,Mapindex'\n",
    "\n",
    "with open('Feature_map.csv', 'w') as file:\n",
    "    file.write(Header + '\\n')\n",
    "    Feature_values = Feature_map_gen(Train, Features, Column, Maps,\n",
    "                                     Special_maps, Index+1)\n",
    "    \n",
    "    for item in Feature_values:\n",
    "        file.write(item[0] + ',' + str(item[1]) + '\\n')\n",
    "        \n",
    "    print('• [File %s]: Process completed!\\n' %('Feature_map.csv'))\n",
    "    \n",
    "#Saving logistic regression files.\n",
    "Header = 'bidid,click,payprice,feature'\n",
    "\n",
    "for key in ['Train', 'Validation']:\n",
    "    Filename = key + '.csv'\n",
    "    \n",
    "    with open(Filename, 'w') as file:\n",
    "        file.write(Header + '\\n')\n",
    "        String_rows = Logistic_regression_gen(Datasets[key], Features, Column,\n",
    "                                              Maps, Special_maps)\n",
    "        \n",
    "        for item in String_rows:\n",
    "            file.write(item + '\\n')\n",
    "        \n",
    "    print('• [File %s]: Process completed!' %Filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
